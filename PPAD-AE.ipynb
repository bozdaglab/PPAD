{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Progression of Alzheimer's Disease Autoencoder (PPAD-AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import fbeta_score,accuracy_score,f1_score,roc_auc_score\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dense, SimpleRNN, concatenate, Input, Flatten\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers import Dropout \n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Masking\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A customized binary cross entropy loss function\n",
    "#𝐿𝑜𝑠𝑠 = −1/𝑁 ∑(𝛼 ∙ (𝑦 ∙ 𝑙𝑜𝑔 𝑦′)) + ((1 − 𝛼) ∙ (1 − 𝑦) ∙ 𝑙𝑜𝑔(1 − 𝑦′))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to panelize positive (converter) misclassification\n",
    "def binary_cross_entropy(y, yhat):\n",
    "    alpha = 0.7\n",
    "    loss = -(tf.math.reduce_mean((alpha * y * tf.math.log(yhat + 1e-6)) + ((1.0- alpha) * (1 - y) * tf.math.log(1 - yhat + 1e-6)), axis=-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPAD-AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPAD method that takes the follwing parametres:\n",
    "# cell: it represents the RNN cell will be used {'GRU', 'biGRU', 'LSTM', 'biLSTM'}\n",
    "# drout: it represents the drop out rate will be used {0, 0.1, 0.2, 0.3, 0.4, 0.5}\n",
    "# L2: it represents the L2 regularization {0.1, 0.001, 0.00001, 0.0000001}\n",
    "# ftp: it represents future time point to predict in PPAD-AE its {2, 3, 4}\n",
    "def PPAD_AE_with_demographic(cell, drout, L2, ftp):\n",
    "    batch_shape = (None, time_steps, num_features_in_each_time_step)\n",
    "    model = Sequential()\n",
    "    model.add(Masking(-1, batch_input_shape=batch_shape))\n",
    "    \n",
    "    if cell == 'biGRU':\n",
    "        model.add(Bidirectional(GRU(16, activity_regularizer=l2(L2), return_sequences=True, activation='relu')))\n",
    "        model.add(Dropout(drout))\n",
    "        model.add(Bidirectional(GRU(8, activity_regularizer=l2(L2), return_sequences=False, activation='relu')))\n",
    "        model.add(Dropout(drout))\n",
    "        model.add(RepeatVector(ftp))\n",
    "        model.add(Bidirectional(GRU(8, activity_regularizer=l2(L2), return_sequences=True, activation='relu')))#activation = 'tanh'\n",
    "        model.add(Dropout(drout))\n",
    "        model.add(Bidirectional(GRU(16, activity_regularizer=l2(L2), return_sequences=False, activation='relu')))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(drout, name='out'))\n",
    "    elif cell == 'biLSTM':\n",
    "        model.add(Bidirectional(LSTM(16, activity_regularizer=l2(L2), return_sequences=True, activation='relu')))\n",
    "        model.add(Dropout(drout))\n",
    "        model.add(Bidirectional(LSTM(8, activity_regularizer=l2(L2), return_sequences=False, activation='relu')))\n",
    "        model.add(Dropout(drout))\n",
    "        model.add(RepeatVector(ftp))\n",
    "        model.add(Bidirectional(LSTM(8, activity_regularizer=l2(L2), return_sequences=True, activation='relu')))#activation = 'tanh'\n",
    "        model.add(Dropout(drout))\n",
    "        model.add(Bidirectional(LSTM(16, activity_regularizer=l2(L2), return_sequences=False, activation='relu')))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(drout, name='out'))\n",
    "    elif cell == 'GRU':\n",
    "        model.add(GRU(16, activity_regularizer=l2(L2), return_sequences=True, activation='relu'))\n",
    "        model.add(Dropout(drout))\n",
    "        model.add(GRU(8, activity_regularizer=l2(L2), return_sequences=False, activation='relu'))\n",
    "        model.add(Dropout(drout))\n",
    "        model.add(RepeatVector(ftp))\n",
    "        model.add(GRU(8, activity_regularizer=l2(L2), return_sequences=True, activation='relu'))#activation = 'tanh'\n",
    "        model.add(Dropout(drout))\n",
    "        model.add(GRU(16, activity_regularizer=l2(L2), return_sequences=False, activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(drout, name='out'))\n",
    "    elif cell == 'LSTM':\n",
    "        model.add(LSTM(16, activity_regularizer=l2(L2), return_sequences=True, activation='relu'))\n",
    "        model.add(Dropout(drout))\n",
    "        model.add(LSTM(8, activity_regularizer=l2(L2), return_sequences=False, activation='relu'))\n",
    "        model.add(Dropout(drout))\n",
    "        model.add(RepeatVector(ftp))\n",
    "        model.add(LSTM(8, activity_regularizer=l2(L2), return_sequences=True, activation='relu'))#activation = 'tanh'\n",
    "        model.add(Dropout(drout))\n",
    "        model.add(LSTM(16, activity_regularizer=l2(L2), return_sequences=False, activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(drout, name='out'))\n",
    "    \n",
    "    #Demographic model\n",
    "    model2 = Input(shape=(demographic_features))\n",
    "    \n",
    "    # concatenating RNN output with demographic data\n",
    "    concat = concatenate([model.get_layer(name='out').output, model2], name='Concatenate')\n",
    "    \n",
    "    # MLP Classification model\n",
    "    final_model_ = Dense(16, activation='relu')(concat)\n",
    "    final_model0 = Dense(8, activation='relu')(final_model_)\n",
    "    final_model1 = Dense(4, activation='relu')(final_model0)\n",
    "    final_model2 = Dense(1, activation='sigmoid')(final_model1)\n",
    "    final_model = Model(inputs=[model.inputs, model2], outputs=final_model2, name='Final_output')\n",
    "    \n",
    "    final_model.compile(loss= binary_cross_entropy, optimizer='adam',metrics=['accuracy'])\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F2 Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fbeata_function method to calculate f2 score\n",
    "def overall_fbeta_function(pred, actual):\n",
    "    # reshape the output\n",
    "    if len(actual.shape) > 2:\n",
    "        actual = np.reshape(actual, (actual.shape[0], actual.shape[1]*actual.shape[2]))\n",
    "    \n",
    "    y = []\n",
    "    \n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(pred.shape[1]):\n",
    "            if pred[i,j] > 0.5:\n",
    "                pred[i,j] = 1\n",
    "            else:\n",
    "                pred[i,j] = 0 \n",
    "    \n",
    "    for i in range(pred.shape[0]):\n",
    "        COUNTER = 0\n",
    "        while (COUNTER < actual.shape[1]):\n",
    "            if actual[i,COUNTER] != -1:\n",
    "                COUNTER+=1\n",
    "            else:\n",
    "                break\n",
    "        y.append(actual[i,COUNTER-1])\n",
    "    y = np.array(y) \n",
    "    y = np.reshape(y, (y.shape[0], 1))\n",
    "    \n",
    "    return fbeta_score(y, pred, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and evaluate model\n",
    "def do_PPAD_AE(longitudinal_train_data, train_label, longitudinal_test_data, test_label, demographic_train_data,\n",
    "               demographic_test_data, iteration, ftp, hp_list):\n",
    "    X_train = longitudinal_train_data\n",
    "    y_train = train_label[:,-1]\n",
    "\n",
    "    X_test = longitudinal_test_data\n",
    "    y_test = test_label[:,-1]\n",
    "    \n",
    "    # hp\n",
    "    batch_size_ = int(hp_list[0])\n",
    "    epochs_ = int(hp_list[1])\n",
    "    drout = hp_list[2]\n",
    "    L2 = hp_list[3]\n",
    "    cell = hp_list[4].strip()\n",
    "    \n",
    "    model = PPAD_AE_with_demographic(cell, drout, L2, ftp)\n",
    "    history = model.fit([X_train, demographic_train_data], y_train, epochs=epochs_, batch_size = batch_size_,\n",
    "                        shuffle = True, verbose=0)\n",
    "    \n",
    "    #train\n",
    "    train_loss, train_acc = model.evaluate([X_train, demographic_train_data], y_train, batch_size = batch_size_, verbose=0)\n",
    "    train_pred = model.predict([X_train, demographic_train_data], verbose=0)\n",
    "    print('Training is over')\n",
    "    \n",
    "    #test\n",
    "    test_loss, test_acc = model.evaluate([X_test, demographic_test_data], y_test, batch_size = batch_size_, verbose=0)\n",
    "    test_pred = model.predict([X_test, demographic_test_data], verbose=0)\n",
    "    print('Test is over')\n",
    "    \n",
    "    # prepare results\n",
    "\n",
    "    for i in range(test_pred.shape[0]):\n",
    "        for j in range(test_pred.shape[1]):\n",
    "            if test_pred[i,j] > 0.5:\n",
    "                test_pred[i,j] = 1\n",
    "            else:\n",
    "                test_pred[i,j] = 0\n",
    "                \n",
    "    predicted_l = np.zeros((len(test_pred)))\n",
    "    real_l = np.zeros((len(y_test)))\n",
    "    dx = test_pred.shape[1] - 1\n",
    "    for i in range(len(test_pred)):\n",
    "        predicted_l[i] = test_pred[i,dx]\n",
    "    for i in range(len(y_test)):\n",
    "        real_l[i] = y_test[i,dx]\n",
    "    CM = confusion_matrix(real_l, predicted_l, labels=[0,1])\n",
    "    \n",
    "    sensitivity = CM[1,1] / (CM[1,1] + CM[1,0])\n",
    "    specificity = CM[0,0] / (CM[0,0] + CM[0,1])\n",
    "    \n",
    "    # Table of results\n",
    "    col = 'Iteration '+str(iteration)\n",
    "    metrics_results_df = pd.DataFrame(columns = [col])\n",
    "\n",
    "    metrics_results_df.loc[len(metrics_results_df)] = [round(accuracy_score(y_test[:, -1], test_pred[:, -1]), 3)]\n",
    "    metrics_results_df.loc[len(metrics_results_df)] = [round(test_loss, 3)]\n",
    "    metrics_results_df.loc[len(metrics_results_df)] = [round(roc_auc_score(y_test[:, -1], test_pred[:, -1]), 3)]\n",
    "    metrics_results_df.loc[len(metrics_results_df)] = [round(fbeta_score(y_test[:, -1], test_pred[:, -1], beta=2), 3)] \n",
    "    metrics_results_df.loc[len(metrics_results_df)] = [round(sensitivity, 3)] \n",
    "    metrics_results_df.loc[len(metrics_results_df)] = [round(specificity, 3)]  \n",
    "    metrics_results_df.loc[len(metrics_results_df)] = [round(train_acc, 3)]\n",
    "    metrics_results_df.loc[len(metrics_results_df)] = [round(train_loss, 3)]\n",
    "    metrics_results_df.loc[len(metrics_results_df)] = [round(overall_fbeta_function(train_pred, y_train), 3)]\n",
    "    \n",
    "    return metrics_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to create and return an empty dataframe for results \n",
    "def create_table():\n",
    "    # Table of results\n",
    "    PPAD_metrics_results_df = pd.DataFrame(columns = ['Metrics'])\n",
    "    PPAD_metrics_results_df.loc[len(PPAD_metrics_results_df)] = ['Accuracy (Test)']\n",
    "    PPAD_metrics_results_df.loc[len(PPAD_metrics_results_df)] = ['Loss (Test)']\n",
    "    PPAD_metrics_results_df.loc[len(PPAD_metrics_results_df)] = ['ROC_AUC (Test)']\n",
    "    PPAD_metrics_results_df.loc[len(PPAD_metrics_results_df)] = ['F-2 (Test)'] \n",
    "    PPAD_metrics_results_df.loc[len(PPAD_metrics_results_df)] = ['Sensitivity (Test)'] \n",
    "    PPAD_metrics_results_df.loc[len(PPAD_metrics_results_df)] = ['Specificity (Test)']  \n",
    "    PPAD_metrics_results_df.loc[len(PPAD_metrics_results_df)] = ['Accuracy (Train)']\n",
    "    PPAD_metrics_results_df.loc[len(PPAD_metrics_results_df)] = ['Loss (Train)']\n",
    "    PPAD_metrics_results_df.loc[len(PPAD_metrics_results_df)] = ['F-2 (Train)']\n",
    "    \n",
    "    return PPAD_metrics_results_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best hyperparameters that have been chosen by grid search optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read a csv file that contains best hyperparameters and copy it in a dataframe\n",
    "# Hyperparameters df contains the best values of batch_size, epoch, dropout, l2, and RNN cell\n",
    "\n",
    "file_name = 'PPAD_hp_df.csv'\n",
    "PPAD_hp_df = read_csv(file_name,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epoch</th>\n",
       "      <th>dropout</th>\n",
       "      <th>l2</th>\n",
       "      <th>cell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>GRU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size  epoch  dropout     l2  cell\n",
       "0           8     50      0.4  0.001   GRU"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPAD_hp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpikle data\n",
    "\n",
    "# Longitudinal training data\n",
    "file_name = 'longitudinal_data_train.pkl'\n",
    "lon_data_train = pd.read_pickle(file_name)\n",
    "\n",
    "# Labels of traing data \n",
    "file_name = 'label_train.pkl'\n",
    "label_train = pd.read_pickle(file_name)\n",
    "\n",
    "# Demographic training data\n",
    "file_name = 'demographic_data_train.pkl'\n",
    "dem_data_train = pd.read_pickle(file_name)\n",
    "\n",
    "# Longitudinal test data\n",
    "file_name = 'longitudinal_data_test.pkl'\n",
    "lon_data_test = pd.read_pickle(file_name)\n",
    "\n",
    "# Labels of test data \n",
    "file_name = 'label_test.pkl'\n",
    "label_test = pd.read_pickle(file_name)\n",
    "\n",
    "# Demographic test data\n",
    "file_name = 'demographic_data_test.pkl'\n",
    "dem_data_test = pd.read_pickle(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This represents number of visits (time points) will be used in the training.\n",
    "time_steps = lon_data_test[0].shape[1]\n",
    "\n",
    "# This represents number of future visits ahead to predict \n",
    "future_time_s = label_test[0].shape[1]\n",
    "\n",
    "# This represents how many featutes in each visit (longitudinal).\n",
    "num_features_in_each_time_step = lon_data_test[0].shape[2]\n",
    "\n",
    "# This represents how many demographic featutes (cross sectional).\n",
    "demographic_features = len(dem_data_test[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runing PPAD-AE 5 times for one scenario and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration_ 1\n",
      "Training is over\n",
      "Test is over\n",
      "PPAD-AE\n",
      "iteration_ 2\n",
      "Training is over\n",
      "Test is over\n",
      "PPAD-AE\n",
      "iteration_ 3\n",
      "Training is over\n",
      "Test is over\n",
      "PPAD-AE\n",
      "iteration_ 4\n",
      "Training is over\n",
      "Test is over\n",
      "PPAD-AE\n",
      "iteration_ 5\n",
      "Training is over\n",
      "Test is over\n",
      "PPAD-AE\n"
     ]
    }
   ],
   "source": [
    "longitudinal_train_data = lon_data_train[0]\n",
    "train_label = label_train[0]\n",
    "longitudinal_test_data = lon_data_test[0]\n",
    "test_label = label_test[0]\n",
    "demographic_train_data = np.array(dem_data_train[0])\n",
    "demographic_test_data = np.array(dem_data_test[0])\n",
    "\n",
    "# HP\n",
    "PPAD_hp_list = list(PPAD_hp_df.iloc[0,:])\n",
    "\n",
    "PPAD_metrics_results_df = create_table()\n",
    "for j in range(5):\n",
    "    print(\"iteration_\", j+1)\n",
    "    #PPAD-AE\n",
    "    PPAD_result = do_PPAD_AE(longitudinal_train_data, train_label, longitudinal_test_data, test_label, demographic_train_data,\n",
    "                          demographic_test_data, j+1, future_time_s, PPAD_hp_list)\n",
    "    PPAD_metrics_results_df = pd.concat([PPAD_metrics_results_df, PPAD_result], axis=1)\n",
    "    print(\"PPAD-AE\")\n",
    "# SAVE RESULTS\n",
    "PPAD_scenario = str(time_steps)+'_'+str(future_time_s)+'_PPAD-AE.csv'\n",
    "PPAD_metrics_results_df.to_csv(PPAD_scenario, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
